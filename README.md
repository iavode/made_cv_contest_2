# made_cv_contest_2
# Описание решения, которое получило мой лучший *score* на *kaggle*.

 Обучение проводилось локально. В качестве рабочей машины использовался:
  * *Acer Nitro 5 Intel i5-9300H 2.40GHz 8GB Ram NVIDIA GeForce GTX 1650 4GB*.

 Так же использовался *colab.research.google.com*.

 В качесте базовой модели была обучена модель предложенная преподавателями. Параметры обученияпредставлены ниже:

* *AdamW(lr=3e-4, weight_decay=0.05);*
  * *ReduceLROnPlateau(patience=2, factor=0.1**0.5);*
  * *n_epochs_det* = 30;*
  * *n_epochs_rec* = 20;*
 
 В результате был получен *score* не сильно отличающийся от *baseline* (0.95893). Для улучшения результатов был проведен поиск лучшей модели ответственной за предсказание нормеров. Были проверены модели:

 * *Resnet34 + GRU;*
 * *Resnet50 + GRU;*
 * *Resnext50_32x4d + GRU.*
 
 Лучший результат показала сеть *Resnext50_32x4d + GRU* был получен score 0.72551. Для улучшения качества обучения было принято решение увеличить количество картинок на которых происходит обучени модели детекции и предсказания.

 Для увеличения количества картинок, с которыми мог работать *pipeline* обучения разработан скрипт, в котором в случайном порядке выбирались *n* аугментация из списка (*Gray, Blur, Sepia, GaussianNoise, Salt&Paper noise, Cutout*). К аугментированной картинке применялся *Crop*. *Crop* был реализован таким образом, что номер всегда оставался в полученной в результате обрезания области. Примененные изменения отражались так же в *json* файле.
 
 ![](img/2_multiplicativenoise.jpg)[](img/3_cutout.jpg)[](img/6_tosepia.jpg)
 
 Увеличение количество картинок позволило улучшить *score* до 0.70480. В качестве модели детекции применялся *Unet* В качестве модели распознования *Resnext50_32x4d + GRU*. Дальнейший подбор гиперпараметров и моделей распознования не давал улучшения результатов. Поэтому было принято решения изменить модель ответственную за детекцию изображения. Были проверены основные моели детекции *fasterrcnn_resnet50_fpn* и *maskrcnn_resnet50*. Основной моделью был взят *maskrcnn_resnet50* (из [tutorial](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html) с сайта Pytorch).
  
  Модель обучалась как на обычном датасете, так и на датасете в с дополнительными аугментированными изображениями. В качестве моделей ответственных за распознование номера применялись модели, описанные выше. Лучший результат был показан при комбинации *maskrcnn_resnet50 + Resnext50_32x4d + GRU*. После получения нового *baseline* началась работа с рутиной обучения. *lr_scheduler* и *optimizer* использовались такие же как и на предыдущих этапах обучения. Основые параметры, которые изменялись во время экспериментов были:
  * *n_epochs;*
  * *picture widht_x_height;*
  * *input dataset;*
  * *rnn params.*
  
 В результате экспериментов былл подобран *pipeline* со следующими парметрами. Использовался датасет с дополнительными аугментированными картинками. В качестве модели детекции использовался maskrcnn_resnet50, полученные параметры масок подавались на вход модели предсказания, которая имела следющие параметры. Модель ответственная за извлечени признаков из изображения номера — *Resnext50_32x4d*, на вход ему подавались номера, которе имеют измененный размер, равный 480x64, в качестве модели предсказания номера использовался *GRU(bidirectional=True, dropout=0.1)*. Обучение модели предсказания проводилось 2 эпохи. Увеличение размера входного номера дало, значительный прирост качества обучения, сравнимый с применением увеличенного по размерам датасета.

 Ниже прикреплен скриншот моего лучшего *score* и моей позиции на *leaderboad*:
![](img/score.png)
